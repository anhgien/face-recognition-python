{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import imutils\n",
    "from imutils.video import VideoStream\n",
    "from imutils.face_utils import FaceAligner\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectFace(face):\n",
    "    (h, w) = face.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(face, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0), swapRB=False, crop=False)\n",
    "    detector.setInput(blob)\n",
    "    detections = detector.forward()\n",
    "    i = np.argmax(detections[0, 0, :, 2])\n",
    "\n",
    "    confidence = detections[0, 0, i, 2]\n",
    "    if confidence < args[\"confidence\"]:\n",
    "        return None\n",
    "\n",
    "    box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "    (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "    (fH, fW) = [endY - startY, endX - startX]\n",
    "\n",
    "    if fH < 20 or fW < 20:\n",
    "        return None\n",
    "\n",
    "    return [startX, startY, endX, endY]\n",
    "\n",
    "def faceToVec(face_aligned):\n",
    "    \n",
    "    faceBlob = cv2.dnn.blobFromImage(face_aligned, 1.0 / 255,\n",
    "\t\t\t\t(96, 96), (0, 0, 0), swapRB=True, crop=False)\n",
    "    net.setInput(faceBlob)\n",
    "    vec = net.forward()\n",
    "\n",
    "    return vec\n",
    "\n",
    "def getFaceImageVec(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    rect = detectFace(img)\n",
    "    if rect is None:\n",
    "        return None\n",
    "\n",
    "    face_aligned = face_aligner.align(img, gray , dlib.rectangle(*rect))\n",
    "    vec = faceToVec(face_aligned)\n",
    "    return vec, rect, img\n",
    "\n",
    "def topMatches(embeddings, vec):\n",
    "    score = np.linalg.norm(embeddings - np.array(vec.flatten()), axis=1)\n",
    "    imatches = np.argsort(score)\n",
    "    score = score[imatches]\n",
    "    return imatches, score\n",
    "\n",
    "def render(image, rect, name, proba):\n",
    "    startX, startY, endX, endY = rect\n",
    "    text = \"{}: {:.2f}%\".format(name, proba * 100)\n",
    "    y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "    cv2.rectangle(image, (startX, startY), (endX, endY),\n",
    "        (0, 0, 255), 2)\n",
    "    cv2.putText(image, text, (startX, y),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
    "    \n",
    "def recognize(frame):\n",
    "    result = getFaceImageVec(frame)\n",
    "    if result is None:\n",
    "        return None\n",
    "\n",
    "    vec, rect, img = result\n",
    "    imatches, score = topMatches(faces, vec)\n",
    "    # showTopMatches(face_aligned, )\n",
    "    imatches = imatches[score < threshold]\n",
    "    print(\"matches: {}, score: {}\".format(names[imatches].tolist(), score[:5].tolist()))\n",
    "    if (len(imatches) == 0):\n",
    "        print(\"unknown face\")\n",
    "        return None\n",
    "    else:\n",
    "        min_distance_label = names[imatches[0]]\n",
    "        preds = clf.predict_proba(vec)[0]\n",
    "        j = np.argmax(preds)\n",
    "        name = le.classes_[j]\n",
    "        proba = preds[j]\n",
    "        print(\"prob: {}, name: {}, min name: {}\".format(proba, name, min_distance_label))\n",
    "        return name, proba, rect, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = cv2.dnn.readNetFromCaffe(\"models/deploy.prototxt\", \"models/res10_300x300_ssd_iter_140000_fp16.caffemodel\")\n",
    "net = cv2.dnn.readNetFromTorch(\"models/openface.nn4.small2.v1.t7\")\n",
    "args = {\n",
    "    \"confidence\": 0.7\n",
    "}\n",
    "pose_predictor=dlib.shape_predictor(\"models/shape_predictor_68_face_landmarks.dat\")\n",
    "face_aligner = FaceAligner(pose_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "matches: ['rose', 'midu', 'midu', 'midu', 'rose', 'rose', 'midu', 'rose', 'midu', 'midu', 'rose', 'rose', 'gien', 'midu', 'midu', 'rose', 'rose', 'midu', 'midu', 'rose', 'rose', 'rose', 'midu', 'midu'], score: [0.4040297567844391, 0.4108780026435852, 0.421395868062973, 0.47616371512413025, 0.4797195792198181]\nprob: 0.4579293095058385, name: rose, min name: rose\n"
     ]
    }
   ],
   "source": [
    "faces = np.load(\"face_embedding.npy\")\n",
    "names = np.load(\"labels.npy\")\n",
    "threshold = 0.6\n",
    "\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(names)\n",
    "clf = SVC(C=1.0, kernel=\"linear\", probability=True)\n",
    "clf.fit(faces, labels)\n",
    "test_file = \"test/rose/rose-3.jpg\"\n",
    "img = imutils.resize(cv2.imread(test_file), width=600)\n",
    "result = recognize(img)\n",
    "\n",
    "if result is not None:\n",
    "    name, proba, rect, image = result\n",
    "    if proba  > args[\"confidence\"]:\n",
    "        render(image, rect, name, proba)\n",
    "    cv2.imshow(name, image)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vs = VideoStream(src=0).start()\n",
    "# time.sleep(2.0)\n",
    "# print(\"Started\")\n",
    "# while True:\n",
    "#     frame = vs.read()\n",
    "#     frame = imutils.resize(frame, width=600)\n",
    "#     recognition = recognize(frame)\n",
    "#     if recognition is not None:\n",
    "#         name, proba, rect, image = recognition\n",
    "#         if proba >= args[\"confidence\"]:\n",
    "#             render(frame, rect, name, proba)\n",
    "#     cv2.imshow(\"Frame\", frame)\n",
    "#     key = cv2.waitKey(1) & 0xFF\n",
    "#     # if the `q` key was pressed, break from the loop\n",
    "#     if key == ord(\"q\"):\n",
    "#         break\n",
    "# cv2.destroyAllWindows()\n",
    "# vs.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}